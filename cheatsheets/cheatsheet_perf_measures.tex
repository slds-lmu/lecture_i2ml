\documentclass[landscape, 10pt, margin=0cm]{article}

\usepackage{geometry}
 \geometry{
 a4paper,
 left=20mm,
 top=20mm,
 }
\usepackage[utf8]{inputenc} % UTF-8
\usepackage[english]{babel} % Language
\usepackage{hyperref} % Hyperlinks
\usepackage{ragged2e} % Text position
\usepackage[export]{adjustbox} % Image position
\usepackage[most]{tcolorbox}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}
\usepackage{booktabs}

\input{../latex-math/basic-math.tex}
\input{../latex-math/basic-ml.tex}
\input{../latex-math/ml-eval.tex}

\begin{document}
\begin{table}[h!]
\centering
\small
%\begin{tabular}{ll >{\raggedleft}p{0.8cm}@{,\hspace{0.15em}}>{\raggedright}p{0.8cm} p{7cm}}
\begin{tabular}{llcc p{9cm}}
\toprule
Name & Formula & Direction & Range & Description \\
\midrule
\multicolumn{5}{l}{\textbf{Performance measures for regression}}\\[0.15em]
Mean Squared Error (MSE)        & $\frac{1}{\ntest} \sum_{i = 1}^{\ntest} \left(\yi - \yih\right)^2 $  & min & $[0, \infty)$ &  Mean of the squared distances between the target variable $y$ and the predicted target $\yh$.\\
Mean Absolute Error (MAE)       & $\frac{1}{\ntest} \sum_{i = 1}^{\ntest} \left\lvert\yi - \yih\right\rvert$ & min & $[0, \infty)$  & More robust than MSE, since it is less influenced by large errors. \\
$R^2$        & $1 - \frac{\sum_{i = 1}^{\ntest} \left(\yi - \yih\right)^2}{\sum_{i = 1}^{\ntest} \left(\yi - \bar{y}\right)^2}$    & max & $(-\infty, 1]$  & Compare the sum of squared errors (SSE) of the model to a constant baseline model. \\ 
\multicolumn{5}{l}{\textbf{Performance measures for classification based on class labels}}\\[0.2em]
Accuracy (ACC)            & $\frac{1}{\ntest} \sum_{i = 1}^{\ntest} \I_{\left\{\yi = \yih\right\}}$                                   & max & $[0, 1]$      & Proportion of correctly classified observations. \\
Balanced Accuracy (BA)    & $\frac{1}{g} \sum_{k=1}^g \frac{1}{n_{\text{test},k}} \sum_{\yi: \yi = k} \I_{\left\{\yi = \yih\right\}}$ & max & $[0, 1]$      & Variant of the accuracy that accounts for imbalanced classes. \\

Classification Error (CE) & $\frac{1}{\ntest} \sum_{i = 1}^{\ntest} \I_{\left\{\yi \neq \yih\right\}}$                                & min & $[0, 1]$      & $\mathrm{CE}=1 - \mathrm{ACC}$ is the proportion of incorrect predictions. \\
ROC measures              & $\mathrm{TPR} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}$                                                & max & $[0, 1]$      & True Positive Rate: how many observations of the positive class 1 are predicted as 1?\\
                          & $\mathrm{FPR} = \frac{\mathrm{FP}}{\mathrm{TN} + \mathrm{FP}}$                                                & min & $[0, 1]$      & False Positive Rate: how many observations of the negative class 0 are falsely predicted as 1? \\
                          & $\mathrm{TNR} = \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FP}}$                                                & max & $[0, 1]$      & True Negative Rate: how many observations of the negative class 0 are predicted as 0?\\
                          & $\mathrm{FNR} = \frac{\mathrm{FN}}{\mathrm{TP} + \mathrm{FN}}$                                                & min & $[0, 1]$      & False Negative Rate: how many observations of the positive class 1 were falsely predicted as 0? \\
                          & $\mathrm{PPV} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}$                                                & max & $[0, 1]$      & Positive Predictive Value: how likely is a predicted 1 a true 1?\\
                          & $\mathrm{NPV} = \frac{\mathrm{TN}}{\mathrm{FN} + \mathrm{TN}}$                                                & max & $[0, 1]$      & Negative Predictive Value: how likely is a predicted 0 a true 0?\\
$F_1$                     & $2 \frac{\mathrm{PPV} \cdot \mathrm{TPR}}{\mathrm{PPV} + \mathrm{TPR}}$                                       & max & $[0, 1]$      & $F_1$ is the harmonic mean of PPV and TPR. Especially useful for imbalanced classes.\\
Cost measure              & $\sum_{i = 1}^{\ntest} C(\yi, \yih)$                                                                          & min & $[0, \infty)$ & Cost of incorrect predictions based on a (usually non-negative) cost matrix $C \in \R^{g,g}$.\\
\multicolumn{5}{l}{\textbf{Performance measures for classification based on class probabilities}}\\[0.2em]
Brier Score (BS)          & $\frac{1}{\ntest} \sum_{i = 1}^{\ntest} \sum_{k = 1}^g \left( \pikxih - \sigma_k(\yi) \right)^2 $             & min & $[0, 1]$      & Measures squared distances of probabilities from the one-hot encoded class labels. \\
Log-Loss (LL)             & $\frac{1}{\ntest} \sum_{i = 1}^{\ntest} \left( - \sum_{k=1}^g \sigma_k(\yi) \log(\pikxih) \right) $           & min & $[0, \infty)$ & A.k.a. Bernoulli, binomial or cross-entropy loss \\

AUC                       &                                                                                                               & max & $[0, 1]$      & Area under the ROC curve.\\
\bottomrule
\multicolumn{5}{p{22.5cm}}{\footnotesize{$\yih$ denotes the predicted label for observation $\xi$. ACC, BA, CE, BS, and LL can be used for multi-class classification with $g$ classes. For AUC, multiclass extensions exist as well. The notation $\I_{\{\cdot\}}$ denotes the indicator function. $\sigma_k(y) = \I_{\{y = k\}}$ is 1 if $y$ is class $k$, 0 otherwise (multi-class one-hot encoding). $n_{\text{test},k}$ is the number of observations in the test set with class $k$. $\pikxh$ is the estimated probability for observation $\xi$ of belonging to class $k$. $TP$ is the number of true positives (observations of class 1 with predicted class 1), $FP$ is the number of false positives (observations of class 0 with predicted class 1), $TN$ is the number of true negatives (observations of class 0 with predicted class 0), and $FN$ is the number of false negatives (observations of class 1 with predicted class 0).}}
\end{tabular}
\caption{Popular performance measures used for ML, assuming an arbitrary test set of size $\ntest$.}
\label{tab:measures}
\end{table}
\end{document}
