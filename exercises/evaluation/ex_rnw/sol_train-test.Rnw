\begin{enumerate}
\item[1)] The generalization error is the expected (future) performance of a learner $\inducer$ trained on $\ntrain$ observations with performance measure $\rho$.
As any such performance estimate depends on the concrete sampling of $\Dtest$ from $\Pxy$, we are interested in the limit of this expectation value, as $\ntest\rightarrow\infty$.
\item[2)] One samples $\Dtrain$ of size $\ntrain = 100$ and $\Dtest$ of size $\ntest$ $K$ times from $\Pxy$ (independently).
Each time, the learner $\inducer$ is trained on $\Dtraini[k]$, and the respective performance $\rho$ is evaluated on $\Dtesti[k]$.
For $K,\ntest\rightarrow\infty$, the average performance $\frac{1}{K}{\sum\limits_{k=1}^K} \rho \left(\yv_{\Jtesti[k]}, {\F_{\Jtesti[k],\inducer(\Dtraini[k])}}\right)$ converges to $\GE(\inducer, \ntrain = 100, \rho)$.
\item[3)] As $\ntrain$ must be smaller than $n$, the estimator is a pessimistically biased estimator of $\GE(\inducer, n, \rho)$, as we are not using all available data for training.
In the context of regression tasks and performance measures MSE or MAE, pessimistic bias means:
\begin{align}
\E\left[{\GEh_{\Jtrain, \Jtest}(\inducer, |\Jtrain|, \rho)}\right] > \GE(\inducer, n, \rho)
\end{align}
\item[4)] If one chooses a large $\ntrain$, $\ntest$ is small, and the estimator has a large variance. 
\end{enumerate}