{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b2c55",
   "metadata": {},
   "source": [
    "***\n",
    "**Introduction to Machine Learning** <br>\n",
    "__[https://slds-lmu.github.io/i2ml/](https://slds-lmu.github.io/i2ml/)__\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3ceb9",
   "metadata": {},
   "source": [
    "# Exercise sheet: 12 Nested Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | label: import\n",
    "# Consider the following libraries for this exercise sheet:\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fd462",
   "metadata": {},
   "source": [
    "## Exercise 2: AutoML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a3d27",
   "metadata": {},
   "source": [
    "In this exercise, we build a simple automated machine learning (AutoML) system that will make data-driven\n",
    "choices on which learner/estimator to use and also conduct the necessary tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb35cd",
   "metadata": {},
   "source": [
    "`sklearn.pipeline.Pipeline` makes this endeavor easy, modular and guarded against many common modeling\n",
    "errors. <br>\n",
    "We work on the [`pima`](https://github.com/slds-lmu/lecture_i2ml/blob/master/exercises/data/pima.csv) data to classify patients as diabetic and design a system that is able to choose between $k$-NN\n",
    "and a random forest, both with tuned hyperparameters. <br>\n",
    "The purpose of the pipeline is to assemble several steps of transformation and a final estimator that can be crossvalidated together while setting different parameters. So to speak, the pipeline estimator can be treated as any\n",
    "other estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8141e",
   "metadata": {},
   "source": [
    "> a) Load the data set [`pima`](https://github.com/slds-lmu/lecture_i2ml/blob/master/exercises/data/pima.csv), encode the target \"`diabetes`\" as $0$-$1$-vector and perform a stratified `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc584df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe876b7",
   "metadata": {},
   "source": [
    "> b) As part of our modeling process, we want to perform certain preprocessing steps. While this step is highly\n",
    "customizable, we want to include at least One-Hot-Encoding of categorical features, and imputing of missing\n",
    "values. <br>\n",
    "Instance a `ColumnTransformer` object and include these two steps for a dynamic choice of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2af67e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Hint:</b>   Strings are considered as <code>dtype = object</code> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0748ad",
   "metadata": {},
   "source": [
    "> c) Next, both pipelines for the $k$-NN and random forest are created. Like this you can create estimators with highly\n",
    "individual preprocessing steps. Include the previously created `ColumnTransformer`, a `VarianceThreshold` to\n",
    "remove constant columns and the corresponding estimator as a final step. Additionally, scale the columns for\n",
    "the $k$-NN estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e61271",
   "metadata": {},
   "source": [
    "> d) A very common ensembling technique is to predict according to the decisions of numerous estimators. This is\n",
    "refered to as `VotingClassifier` and enables you to predict the class label based on the argmax of the sums\n",
    "of the predicted probabilities. Instanciate a `VotingClassifier` with the two classifier pipelines for $k$-NN and\n",
    "random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c500006",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Hint:</b> set the parameters `<code>voting = \"soft\"</code> and <code>n_jobs = -1</code> for parallel computation. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa7652",
   "metadata": {},
   "source": [
    "> e) Now you have an estimator object just like any other. Take a look at its tunable hyperparameters. You will\n",
    "optimize the number of neighbors in $k$-NN (between $3$ and $10$), and the number of split candidates to try in the\n",
    "random forest (between $1$ and $5$). Define the search range for each like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_voting = [{\"<voting_estimator1>__<pipelie1_estimator>__<hyperparameter>\":\n",
    "                        list(<parameter_range>)},\n",
    "                    {\"<voting_estimator2>__<pipelie2_estimator>__<hyperparameter>\":\n",
    "                        list(<parameter_range>)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8b388",
   "metadata": {},
   "source": [
    "> Please note, that the estimator names should be on par with the labels given in the `VotingClassifier`, the\n",
    "`Pipeline` and, of course, the hyperparameter of the used estimator in the pipeline. Each level of hyperparameters of our created ensemble estimator is accessable through the seperation ”__” (double underscore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b503e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac9d7c",
   "metadata": {},
   "source": [
    "> f) Nested Resampling is a method to avoid the so called *optimization bias* by tuning parameters and evaluation\n",
    "performance on different subsets of your training data. Use\n",
    "> - Stratified $3$-CV in both inner and outer loop.\n",
    "> - accuracy as inner performance measure,\n",
    "> - grid search as tuning algorithm. <br>\n",
    "\n",
    "> You may use the following, incomplete code to compute the nested resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OUTER_FOLDS = <...>\n",
    "nested_scores_voting = np.zeros(NUM_OUTER_FOLDS) # initalize scores with 0\n",
    "# Choose cross-validation techniques for the inner and outer loops,\n",
    "# independently of the dataset.\n",
    "# E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "inner_cv = <...>(n_splits=<...>, shuffle=True, random_state=42)\n",
    "outer_cv = <...>(n_splits=<...>, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(outer_cv.split(X_train, y_train)):\n",
    "    # Nested CV with parameter optimization for ensemble pipeline\n",
    "    clf_gs_voting = <...>(\n",
    "        estimator=<...>,\n",
    "        param_grid=<...>,\n",
    "        cv=<...>,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf_gs_voting.fit(X_train.iloc[<...>], y_train[<...>])\n",
    "    nested_scores_voting[i] = clf_gs_voting.score(X_train.iloc[<...>], y_train[<...>])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f937bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752c811",
   "metadata": {},
   "source": [
    "> g) Extract performance estimates per outer fold and overall (as mean). According to your results, determin the\n",
    "best classifier object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48af35",
   "metadata": {},
   "source": [
    "> h) Lastly, evaluate the performance on the test set. Think about the imbalance of your data set and how this is\n",
    "affecting the performance measurement accuracy. Try to find a better metric and compare these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c08603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f404d95",
   "metadata": {},
   "source": [
    "Congrats, you just designed a turn-key AutoML system that does (nearly) all the work with a few lines of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b4095",
   "metadata": {},
   "source": [
    "## Exercise 3: Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20a4ad",
   "metadata": {},
   "source": [
    "Make yourself familiar with the Titanic Kaggle challenge [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic). <br>\n",
    "Based on everything you have learned in this course, do your best to achieve a good performance in the survival\n",
    "challenge.\n",
    "- Try out different classifiers you have encountered during the course (or maybe even something new?)\n",
    "- Improve the prediction by creating new features (feature engineering).\n",
    "- Tune your parameters (see: https://scikit-learn.org/stable/modules/grid_search.html).\n",
    "- How do you fare compared to the public leaderboard?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (I2ML)",
   "language": "python",
   "name": "python-i2ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}