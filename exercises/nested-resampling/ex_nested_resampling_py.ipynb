{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da9b2c55",
      "metadata": {},
      "source": [
        "***\n",
        "**Introduction to Machine Learning** <br>\n",
        "__[https://slds-lmu.github.io/i2ml/](https://slds-lmu.github.io/i2ml/)__\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d3ceb9",
      "metadata": {},
      "source": [
        "# Exercise sheet: 12 Nested Resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ec11d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: import\n",
        "# Consider the following libraries for this exercise sheet:\n",
        "\n",
        "# general\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "924fd462",
      "metadata": {},
      "source": [
        "## Exercise 2: AutoML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "400a3d27",
      "metadata": {},
      "source": [
        "In this exercise, we build a simple automated machine learning (AutoML) system that will make data-driven\n",
        "choices on which learner/estimator to use and also conduct the necessary tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05cb35cd",
      "metadata": {},
      "source": [
        "`sklearn.pipeline.Pipeline` makes this endeavor easy, modular and guarded against many common modeling\n",
        "errors. <br>\n",
        "We work on the [`pima`](https://github.com/slds-lmu/lecture_i2ml/blob/master/exercises/data/pima.csv) data to classify patients as diabetic and design a system that is able to choose between $k$-NN\n",
        "and a random forest, both with tuned hyperparameters. <br>\n",
        "The purpose of the pipeline is to assemble several steps of transformation and a final estimator that can be crossvalidated together while setting different parameters. So to speak, the pipeline estimator can be treated as any\n",
        "other estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f8141e",
      "metadata": {},
      "source": [
        "> a) Load the data set [`pima`](https://github.com/slds-lmu/lecture_i2ml/blob/master/exercises/data/pima.csv), encode the target \"`diabetes`\" as $0$-$1$-vector and perform a stratified `train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc584df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe876b7",
      "metadata": {},
      "source": [
        "> b) As part of our modeling process, we want to perform certain preprocessing steps. While this step is highly\n",
        "customizable, we want to include at least One-Hot-Encoding of categorical features, and imputing of missing\n",
        "values. <br>\n",
        "Instance a `ColumnTransformer` object and include these two steps for a dynamic choice of columns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d2af67e",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Hint:</b>   Strings are considered as <code>dtype = object</code> <br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b869f216",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae0748ad",
      "metadata": {},
      "source": [
        "> c) Next, both pipelines for the $k$-NN and random forest are created. Like this you can create estimators with highly\n",
        "individual preprocessing steps. Include the previously created `ColumnTransformer`, a `VarianceThreshold` to\n",
        "remove constant columns and the corresponding estimator as a final step. Additionally, scale the columns for\n",
        "the $k$-NN estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b760f91c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e61271",
      "metadata": {},
      "source": [
        "> d) A very common ensembling technique is to predict according to the decisions of numerous estimators. This is\n",
        "refered to as `VotingClassifier` and enables you to predict the class label based on the argmax of the sums\n",
        "of the predicted probabilities. Instanciate a `VotingClassifier` with the two classifier pipelines for $k$-NN and\n",
        "random forest."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c500006",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Hint:</b> set the parameters `<code>voting = \"soft\"</code> and <code>n_jobs = -1</code> for parallel computation. <br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e863222b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40fa7652",
      "metadata": {},
      "source": [
        "> e) Now you have an estimator object just like any other. Take a look at its tunable hyperparameters. You will\n",
        "optimize the number of neighbors in $k$-NN (between $3$ and $10$), and the number of split candidates to try in the\n",
        "random forest (between $1$ and $5$). Define the search range for each like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a0ad2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_voting = [{\"<voting_estimator1>__<pipelie1_estimator>__<hyperparameter>\":\n",
        "                        list(<parameter_range>)},\n",
        "                    {\"<voting_estimator2>__<pipelie2_estimator>__<hyperparameter>\":\n",
        "                        list(<parameter_range>)}]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e8b388",
      "metadata": {},
      "source": [
        "> Please note, that the estimator names should be on par with the labels given in the `VotingClassifier`, the\n",
        "`Pipeline` and, of course, the hyperparameter of the used estimator in the pipeline. Each level of hyperparameters of our created ensemble estimator is accessable through the seperation \u201d__\u201d (double underscore)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b503e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ac9d7c",
      "metadata": {},
      "source": [
        "> f) Nested Resampling is a method to avoid the so called *optimization bias* by tuning parameters and evaluation\n",
        "performance on different subsets of your training data. Use\n",
        "> - Stratified $3$-CV in both inner and outer loop.\n",
        "> - accuracy as inner performance measure,\n",
        "> - grid search as tuning algorithm. <br>\n",
        "\n",
        "> You may use the following, incomplete code to compute the nested resampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69aa21eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_OUTER_FOLDS = <...>\n",
        "nested_scores_voting = np.zeros(NUM_OUTER_FOLDS) # initalize scores with 0\n",
        "# Choose cross-validation techniques for the inner and outer loops,\n",
        "# independently of the dataset.\n",
        "# E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
        "inner_cv = <...>(n_splits=<...>, shuffle=True, random_state=42)\n",
        "outer_cv = <...>(n_splits=<...>, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(outer_cv.split(X_train, y_train)):\n",
        "    # Nested CV with parameter optimization for ensemble pipeline\n",
        "    clf_gs_voting = <...>(\n",
        "        estimator=<...>,\n",
        "        param_grid=<...>,\n",
        "        cv=<...>,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    clf_gs_voting.fit(X_train.iloc[<...>], y_train[<...>])\n",
        "    nested_scores_voting[i] = clf_gs_voting.score(X_train.iloc[<...>], y_train[<...>])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f937bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5752c811",
      "metadata": {},
      "source": [
        "> g) Extract performance estimates per outer fold and overall (as mean). According to your results, determin the\n",
        "best classifier object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e935c615",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a48af35",
      "metadata": {},
      "source": [
        "> h) Lastly, evaluate the performance on the test set. Think about the imbalance of your data set and how this is\n",
        "affecting the performance measurement accuracy. Try to find a better metric and compare these two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56c08603",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f404d95",
      "metadata": {},
      "source": [
        "Congrats, you just designed a turn-key AutoML system that does (nearly) all the work with a few lines of code!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f81b4095",
      "metadata": {},
      "source": [
        "## Exercise 3: Kaggle Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f20a4ad",
      "metadata": {},
      "source": [
        "Make yourself familiar with the Titanic Kaggle challenge [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic). <br>\n",
        "Based on everything you have learned in this course, do your best to achieve a good performance in the survival\n",
        "challenge.\n",
        "- Try out different classifiers you have encountered during the course (or maybe even something new?)\n",
        "- Improve the prediction by creating new features (feature engineering).\n",
        "- Tune your parameters (see: https://scikit-learn.org/stable/modules/grid_search.html).\n",
        "- How do you fare compared to the public leaderboard?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7b973c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (I2ML)",
      "language": "python",
      "name": "python-i2ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}