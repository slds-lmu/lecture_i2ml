\begin{enumerate} [a)]

  \item $k$-NN classification
  
  \begin{enumerate}[i)]
    \item $k = 3$ $\Longrightarrow$ 2 circles and 1 triangle, so we predict 
    "circle".

<<echo=FALSE, message=FALSE, fig.align="left", fig.height = 2, fig.width=2>>=
x <- c(4, 7, 9, 4, 6, 7, 9, 7, 8)
y <- c(6, 3, 8, 9, 5, 8, 7, 6, 5)
z <- as.factor(c(1, 1, 1, 0, 0, 0, 0, 2, 1))

d3 = c(5, 7, 9, 7)
v3 = c(6 , 8, 6, 4)

d5 = c(4, 7, 10, 7)
v5 = c(6, 9, 6, 3)

d7 = c(3, 7, 10, 10, 7)
v7 = c(6, 10, 7, 5, 2)

library(ggplot2)
qplot(x, y, shape = z, col = z) + 
  theme_bw() +
  theme(legend.position="none") +
  scale_x_continuous(
    minor_breaks = seq(0, 10, by = 1),
    breaks = seq(0, 10, by = 1), 
    limits = c(0, 10)) +
  scale_y_continuous(
    minor_breaks = seq(0, 10, by = 1), 
    breaks = seq(0, 10, by = 1),
    limits = c(0, 10)) +
  annotate("polygon", x = d3, y = v3, alpha = 0.2, fill = "black")

@

    \item[b)] $k = 5$ $\Longrightarrow$ 3 circles and 3 triangles, we have to 
    specify beforehand what to do in case of a tie.

<<echo=FALSE, message=FALSE, fig.align="left", fig.height = 2, fig.width=2>>=
qplot(x, y, shape = z, col = z) + 
  theme_bw() +
  theme(legend.position="none") +
  scale_x_continuous(
    minor_breaks = seq(0, 10, by = 1),
    breaks = seq(0, 10, by = 1), 
    limits = c(0, 10)) +
  scale_y_continuous(
    minor_breaks = seq(0, 10, by = 1), 
    breaks = seq(0, 10, by = 1),
    limits = c(0, 10)) +
  annotate("polygon", x = d5, y = v5, alpha = 0.2, fill = "black")
@

    \item[c)] $k = 7$ $\Longrightarrow$ 3 circles and 4 triangles, so we 
    predict "triangle".

<<echo=FALSE, message=FALSE, fig.align="left", fig.height = 2, fig.width=2>>=
qplot(x, y, shape = z, col = z) + 
  theme_bw() +
  theme(legend.position="none") +
  scale_x_continuous(
    minor_breaks = seq(0, 10, by = 1),
    breaks = seq(0, 10, by = 1), 
    limits = c(0, 10)) +
  scale_y_continuous(
    minor_breaks = seq(0, 10, by = 1), 
    breaks = seq(0, 10, by = 1),
    limits = c(0, 10)) +
  annotate("polygon", x = d7, y = v7, alpha = 0.2, fill = "black")
@

  \end{enumerate}
  
  \item $k$-NN regression
  
  We now consider both unweighted and weighted predictions. 
  Recall that weights are computed based on the distance between the 
  point of interest and its respective neighbors.
  With the Manhattan, or "city block" metric, the distance can be read from 
  the plot by walking along the grid lines (shortest way).
  For example, in the 3-neighborhood, all points have a distance of 2 from our 
  square, so all get weights $\tfrac{1}{2}$.
  
  \begin{enumerate}[i)]
  
    \item $k = 3$
    
    \begin{align*}
      \hat{y} =& \frac{2 + 2 + 4}{3} = \frac{8}{3} \approx 2.67 \\
      \hat{y}_\mathrm{weighted} =& \frac{\frac{1}{2}\cdot 2 + \frac{1}{2}\cdot 
      2 + \frac{1}{2}\cdot 4}{\frac{3}{2}} = \frac{8}{3} \approx 2.67 \\
    \end{align*}
    
    \item $k = 5$
    
    \begin{align*}
      \hat{y} =& \frac{3 \cdot 2 + 3 \cdot 4}{6} = 3 \\
      \hat{y}_\mathrm{weighted} =& \frac{\frac{1}{2}\cdot 2 + \frac{1}{2}\cdot2 
      + \frac{1}{3} \cdot 2 +  \frac{1}{2}\cdot 4 + \frac{1}{3}\cdot 4 + 
      \frac{1}{3}\cdot 4}{\frac{5}{2}} = \frac{44}{15} \approx 2.93\\
    \end{align*}
    
    \item $k = 7$
    
    \begin{align*}
      \hat{y} =& \frac{3 \cdot 2 + 4 \cdot 4}{7} = \frac{22}{7} \approx 
      3.14\\
      \hat{y}_\mathrm{weighted} =& \frac{\frac{1}{2}\cdot 2 + \frac{1}{2}
      \cdot2 + \frac{1}{3} \cdot 2 +  \frac{1}{2}\cdot 4 + \frac{1}{3}\cdot 4 + 
      \frac{1}{3} \cdot 4 + \frac{1}{4} \cdot 4}{\frac{11}{4}} = \frac{100}{33} 
      \approx 3.03\\
    \end{align*}

  \end{enumerate}

\end{enumerate}


  
