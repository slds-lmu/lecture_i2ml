
%Estimate Number of Parameters for LogReg, LDA, QDA, NB

\begin{enumerate}

    % \item 
    % \begin{itemize}
    % 
    % \item \textbf{Binary Logistic Regression (\( K = 2 \)):}  
    % We model:
    % \[
    % P(y = 1 \mid \mathbf{x}) = s(\beta_0 + \beta_1 x_1 + \dots + \beta_p x_p) \text{, where }  s(z) = \dfrac{1}{1 + e^{-z}}.\]
    % 
    % \textbf{Parameters to Estimate:}
    % \begin{itemize}
    %     \item Intercept: \( \beta_0 \) (1 parameter)
    %     \item Coefficients: \( \beta_j \) for \( j = 1, \dots, p \) (\( p \) parameters)
    % \end{itemize}
    % 
    % \textbf{Total Parameters:} \( p + 1 \)
    % 
    % \item \textbf{Multinomial Logistic Regression (\( K > 2 \)):}  
    % Using one class as reference (as $\sum_{k=1}^K P(y = k \mid \mathbf{x}) = 1$):
    % \[
    % P(y = k \mid \mathbf{x}) = \dfrac{\exp(\beta_{0k} + \beta_{1k} x_1 + \dots + \beta_{pk} x_p)}{1 + \sum_{l=1}^{K-1} \exp(\beta_{0l} + \beta_{1l} x_1 + \dots + \beta_{pl} x_p)}, \quad k = 1, \dots, K-1.
    % \]
    % 
    % \textbf{Total Parameters:} \( (K - 1)(p + 1) \)
    % \end{itemize}
    
    \item \textbf{Linear Discriminant Analysis (LDA)}  

    Assuming \( \mathbf{x} \mid y = k \sim \mathcal{N}(\boldsymbol{\mu}_k, \Sigma) \).

    \textbf{Parameters to Estimate:}
    \begin{itemize}
        \item Class Priors: \( \pi_k \) (\( K - 1 \) parameters)
        \item Class Means: \( \boldsymbol{\mu}_k \) (\( Kp \) parameters)
        \item Shared Covariance Matrix \( \Sigma \): symmetric \( p \times p \) matrix (\( \dfrac{p(p + 1)}{2} \) parameters)
    \end{itemize}

    \textbf{Total Parameters:}
    \[
    (K - 1) + Kp + \dfrac{p(p + 1)}{2}
    \]

    \item \textbf{Quadratic Discriminant Analysis (QDA)}  

    Assuming \( \mathbf{x} \mid y = k \sim \mathcal{N}(\boldsymbol{\mu}_k, \Sigma_k) \).

    \textbf{Parameters to Estimate:}
    \begin{itemize}
        \item Class Priors: \( \pi_k \) (\( K - 1 \) parameters)
        \item Class Means: \( \boldsymbol{\mu}_k \) (\( Kp \) parameters)
        \item Class Covariance Matrices \( \Sigma_k \): each symmetric \( p \times p \) matrix (\( K \times \dfrac{p(p + 1)}{2} \) parameters)
    \end{itemize}

    \textbf{Total Parameters:}
    \[
    (K - 1) + Kp + K \times \dfrac{p(p + 1)}{2}
    \]

    \item \textbf{Naive Bayes (Gaussian Features)}  

    Assuming independence between features given the class:
    \[
    x_j \mid y = k \sim \mathcal{N}(\mu_{jk}, \sigma_{jk}^2), \quad j = 1, \dots, p.
    \]

    \textbf{Parameters to Estimate:}
    \begin{itemize}
        \item Class Priors: \( \pi_k \) (\( K - 1 \) parameters)
        \item Means: \( \mu_{jk} \) (\( Kp \) parameters)
        \item Variances: \( \sigma_{jk}^2 \) (\( Kp \) parameters)
    \end{itemize}

    \textbf{Total Parameters:}
    \[
    (K - 1) + 2Kp
    \]

    % \item \textbf{Summary of Total Parameters}
    % 
    % \begin{itemize}
    %     \item \textbf{Binary Logistic Regression (\( K = 2 \)):}
    %     \[
    %     \text{Total Parameters} = p + 1
    %     \]
    %     \item \textbf{Multinomial Logistic Regression (\( K > 2 \)):}
    %     \[
    %     \text{Total Parameters} = (K - 1)(p + 1)
    %     \]
    %     \item \textbf{Linear Discriminant Analysis (LDA):}
    %     \[
    %     \text{Total Parameters} = (K - 1) + Kp + \dfrac{p(p + 1)}{2}
    %     \]
    %     \item \textbf{Quadratic Discriminant Analysis (QDA):}
    %     \[
    %     \text{Total Parameters} = (K - 1) + Kp + K \times \dfrac{p(p + 1)}{2}
    %     \]
    %     \item \textbf{Naive Bayes (Gaussian Features):}
    %     \[
    %     \text{Total Parameters} = (K - 1) + 2Kp
    %     \]
    % \end{itemize}

\end{enumerate}