%\section*{Data C (missing value in $X_1$)}

\begin{enumerate}
\item \textbf{Best first split discarding rows with NA:}

Parent node contains all 4 observations with $Y = \{0, 4, 6, 9\}$.
\begin{compactitem}
    \item Parent node size: $m=4$
    \item Parent mean: $\bar{y} = \frac{0+4+6+9}{4} = \frac{19}{4} = 4.75$
    \item Parent risk: $(0-4.75)^2 + (4-4.75)^2 + (6-4.75)^2 + (9-4.75)^2 = 42.75$
\end{compactitem}

\textbf{Feature $X_1$:} Only usable rows are $\{1,2,4\}$ (row 3 has NA), so $m_{X_1}=3$.

Using only observations $\{1,2,4\}$ with $X_1 = \{1.0, 2.0, 4.0\}$ and $Y = \{0, 4, 9\}$:
\begin{itemize}
    \item Parent mean (on usable rows): $\frac{0+4+9}{3} = \frac{13}{3} \approx 4.33$
    \item Parent risk (on usable rows): $(0-\tfrac{13}{3})^2 + (4-\tfrac{13}{3})^2 + (9-\tfrac{13}{3})^2 = \tfrac{169}{9} + \tfrac{1}{9} + \tfrac{196}{9} = \tfrac{122}{3} \approx 40.67$
    \item Candidate split points: $\{1.5, 3.0\}$ (mid-points of $\{1.0, 2.0, 4.0\}$)
\end{itemize}

\emph{Split at $X_1 < 1.5$:}
\begin{compactitem}
    \item Left: obs $\{1\}$ with $Y=\{0\}$, mean $= 0$, risk $= 0$
    \item Right: obs $\{2,4\}$ with $Y=\{4,9\}$, mean $= 6.5$, risk $= (4-6.5)^2 + (9-6.5)^2 = 6.25 + 6.25 = 12.5$
    \item Total post-split risk: $0 + 12.5 = 12.5$
\end{compactitem}

\emph{Split at $X_1 < 3.0$:}
\begin{compactitem}
    \item Left: obs $\{1,2\}$ with $Y=\{0,4\}$, mean $= 2$, risk $= (0-2)^2 + (4-2)^2 = 4 + 4 = 8$
    \item Right: obs $\{4\}$ with $Y=\{9\}$, mean $= 9$, risk $= 0$
    \item Total post-split risk: $8 + 0 = 8$
\end{compactitem}

The best split on $X_1$ (discarding the row with missing $X_1$) is therefore at $X_1 < 3.0$ with post-split risk $8$ and improvement $\tfrac{122}{3} - 8 = \tfrac{98}{3} \approx 32.67$ relative to the parent node (on usable rows).

\textbf{Feature $X_2$:} All rows available, so $m_{X_2}=4$.

Using all observations with $X_2 = \{2.0, 2.1, 2.2, 3.0\}$ and $Y = \{0, 4, 6, 9\}$:
\begin{itemize}
    \item Parent mean: $\frac{0+4+6+9}{4} = 4.75$
    \item Parent risk: $(0-4.75)^2 + (4-4.75)^2 + (6-4.75)^2 + (9-4.75)^2 = 42.75$
    \item Candidate split points: $\{2.05, 2.15, 2.6\}$ (mid-points of $\{2.0, 2.1, 2.2, 3.0\}$)
\end{itemize}

\emph{Split at $X_2 < 2.05$:}
\begin{compactitem}
    \item Left: obs $\{1\}$ with $Y=\{0\}$, mean $= 0$, risk $= 0$
    \item Right: obs $\{2,3,4\}$ with $Y=\{4,6,9\}$, mean $= 19/3 \approx 6.33$, risk $= (4-6.33)^2 + (6-6.33)^2 + (9-6.33)^2 = 38/3 \approx 12.67$
    \item Total post-split risk: $0 + 38/3 = 38/3 \approx 12.67$, improvement $= 42.75 - 38/3 \approx 30.08$
\end{compactitem}

\emph{Split at $X_2 < 2.15$:}
\begin{compactitem}
    \item Left: obs $\{1,2\}$ with $Y=\{0,4\}$, mean $= 2$, risk $= (0-2)^2 + (4-2)^2 = 4 + 4 = 8$
    \item Right: obs $\{3,4\}$ with $Y=\{6,9\}$, mean $= 7.5$, risk $= (6-7.5)^2 + (9-7.5)^2 = 2.25 + 2.25 = 4.5$
    \item Total post-split risk: $8 + 4.5 = 12.5$, improvement $= 42.75 - 12.5 = 30.25$
\end{compactitem}

\emph{Split at $X_2 < 2.6$:}
\begin{compactitem}
    \item Left: obs $\{1,2,3\}$ with $Y=\{0,4,6\}$, mean $= 10/3 \approx 3.33$, risk $= (0-3.33)^2 + (4-3.33)^2 + (6-3.33)^2 = 56/3 \approx 18.67$
    \item Right: obs $\{4\}$ with $Y=\{9\}$, mean $= 9$, risk $= 0$
    \item Total post-split risk: $56/3 + 0 = 56/3 \approx 18.67$, improvement $= 42.75 - 56/3 \approx 24.08$
\end{compactitem}

\textbf{Best split without adjustment:} $X_1 < 3.0$ with improvement $\tfrac{98}{3} \approx 32.67$ is chosen (better than the best $X_2$ split with improvement $30.25$).

\item \textbf{Using adjusted improvement:}

The adjusted improvement formula is: $\Delta^{\mathrm{adj}}_j = \frac{m_j}{m}\,(R_{\text{parent on }j} - R_{\text{children on }j})$

\textbf{Feature $X_1$:} Adjusted improvement = $\frac{3}{4} \times \tfrac{98}{3} \approx 24.5$.

\textbf{Feature $X_2$:} Adjusted improvement = $\frac{4}{4} \times 30.25 = 30.25$ (for the split at $2.15$).

\textbf{Best split with adjustment:} $\boxed{X_2 < 2.15}$ with adjusted improvement $30.25$.

\item \textbf{Comparison and explanation:}

Without adjustment, we would choose $X_1 < 3.0$ (improvement $\tfrac{98}{3} \approx 32.67$). With adjustment, we choose $X_2 < 2.15$ (adjusted improvement $30.25$).

\textbf{Why adjustment helps:} The adjustment down-weights improvements by the fraction of usable rows ($m_j/m$). This prevents the algorithm from being biased toward features that appear to perform well simply because they were evaluated on fewer (possibly more homogeneous) observations due to missing values.

\item \textbf{How surrogate splits tackle the NA issue:}

Surrogate splits provide a solution to the missing value problem in decision trees by creating backup rules that can route observations when the primary split feature has missing values. Here's how they work:

\begin{enumerate}
\renewcommand{\labelenumii}{(\roman{enumii})}
    \item \textbf{Primary split selection:} Choose the best split using available (non-missing) data for each feature.

    \item \textbf{Surrogate rule creation:} For the chosen primary split, find alternative splits using other features that best mimic the primary split's partitioning behavior.

    \item \textbf{Agreement ranking:} Rank surrogate splits by their agreement with the primary split, where agreement measures how often both rules send observations to the same child node.

    \item \textbf{Routing with missing values:} When an observation has a missing value in the primary split feature, use the best available surrogate split to determine which child node it should go to.

    \item \textbf{Fallback hierarchy:} If multiple features have missing values, use the surrogate splits in order of decreasing agreement until a usable rule is found.
\end{enumerate}
\end{enumerate}

