---
title: "Exercise 1 -- ML Basics"
subtitle: "[Introduction to Machine Learning](https://slds-lmu.github.io/i2ml/)"
---

::: {.content-hidden when-format="pdf"}
::: {.hidden}
{{< include ../_quarto/latex-math.qmd >}}
:::
:::

## Exercise 1: HRO in coding frameworks

Throughout the lecture, we will frequently use the `R` package 
`mlr3`, resp. the `Python` package 
`sklearn`, and its descendants, providing an integrated ecosystem for all 
common machine learning tasks.
Let's recap the HRO principle and see how it is reflected in either `mlr3` or `sklearn`.
An overview of the most important objects and their usage, illustrated with 
numerous examples, can be found at [the `mlr3` book](https://mlr3book.mlr-org.com/) and
[the `scikit` documentation](https://scikit-learn.org/stable/index.html).

(@) How are the key concepts (i.e., hypothesis space, risk and optimization) 
  you learned about in the lecture videos implemented?
  
::: {.content-visible when-profile="solution"}
<details> 
<summary>**Solution**</summary>
::: {.panel-tabset}

### R
Model classes representing a certain **hypothesis** are stored in `learner` objects. Before training them on actual
data, they just contain information on the functional form of $f$. Once a learner has been trained we can examine
the parameters of the resulting model. The empirical **risk** can be assessed after training by several performance
measures (e.g., based on $L2$ loss). **Optimization** happens rather implicitly as `mlr3` only acts as a wrapper for
existing implementations and calls package-specific optimization procedures.

### Python
{{< embed _python.ipynb#hro echo=true >}}
:::
</details> 
:::

(@) Have a look at`mlr3::tsk("iris")` / `sklearn.datasets.load_iris`. What attributes does this object store?

::: {.content-visible when-profile="solution"}
<details> 
<summary>**Solution**</summary>
::: {.panel-tabset}

### R

### Python
{{< embed _python.ipynb#iris echo=true >}}
:::
</details> 
:::

(@) Instantiate a regression tree learner. What are the different settings for this learner?
  * `R` Hint: use `lrn("regr.rpart")` (`mlr3::mlr_learners$keys()` shows all available learners).
  * `Python` Hint: use the `DecisionTreeRegressor` module and use `get_params()` to see all available settings.
  
::: {.content-visible when-profile="solution"}
<details> 
<summary>**Solution**</summary>
::: {.panel-tabset}

### R

### Python
{{< embed _python.ipynb#learner echo=true >}}
:::
</details> 
:::

## Exercise 2: Loss functions for regression tasks

{{< include _ex_loss_functions.qmd >}}

## Exercise 3: Polynomial regression

{{< include _ex_polynomial.qmd >}}

## Exercise 4: Predicting `abalone`

{{< include _ex_abalone.qmd >}}

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.

::: {.content-visible when-profile="solution"}
::: {.content-visible when-format="pdf"}
## Solution
Lorem ipsum dolor sit amet.
:::
::: {.content-visible when-format="html"}
<details>
  <summary>Solution</summary>
  Lorem ipsum dolor sit amet.
</details>
:::
:::

::: {.panel-tabset}
## R

## Python
foo # bug: needs text between embeddings ([issue](https://github.com/quarto-dev/quarto-cli/issues/5255))
:::

::: {.content-visible when-profile="hf"}
::: {.content-visible when-format="pdf"}
# [Deep-dive for Major Statistics] Exercise 1$\ast$: Bar
$$(x - 3)^2 = 5 \in \Amat, \epsm$$
:::
::: {.content-visible when-format="html"}
# Exercise 1$\ast$: Bar
$$(x - 3)^2 = 5 \in \Amat, \epsm$$
:::
:::

