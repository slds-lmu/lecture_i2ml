{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0cd1bb33",
      "metadata": {},
      "source": [
        "***\n",
        "**Introduction to Machine Learning** <br>\n",
        "__[https://slds-lmu.github.io/i2ml/](https://slds-lmu.github.io/i2ml/)__\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a25043",
      "metadata": {},
      "source": [
        "# Exercise sheet 11: Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea93bbe9",
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: import\n",
        "# Consider the following libraries for this exercise sheet:\n",
        "\n",
        "# general\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import validation_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbb6337",
      "metadata": {},
      "source": [
        "## Exercise 3: Tuning $k$-NN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f1d651",
      "metadata": {},
      "source": [
        "In this exercise we will perform hyperparameter optimization (HPO) for the task of classifying the `credit risk`\n",
        "data with a $k$-NN classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1015740",
      "metadata": {},
      "source": [
        "The `KNeighborsClassifier` implementation used by `sklearn` contains several hyperparameters, three of which\n",
        "are to be tuned for our prediction:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a275d72",
      "metadata": {},
      "source": [
        "- `n_neighbors`\n",
        "- `weigths`\n",
        "- `metric`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c84fef",
      "metadata": {},
      "source": [
        "> a) Describe briefly the role of each hyperparameter in the learning algorithm \u2013 which effects can be expected by\n",
        "altering them? Furthermore, read the [credit_for_py.csv](https://github.com/slds-lmu/lecture_i2ml/blob/master/exercises/data/german_credit_for_py.csv), separate $138$ test observations and perform necessary\n",
        "preprocessing steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b9b8cad",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Hint:</b>  Apply a <code>StandardScaler</code> on your feature space. What effect does scaling have on your k-NN-model?<br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e755d26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import the data:\n",
        "german_credit = pd.read_csv(\"https://raw.githubusercontent.com/slds-lmu/lecture_i2ml/master/exercises/data/credit_for_py.csv\")\n",
        "\n",
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9bd8b7",
      "metadata": {},
      "source": [
        "> b) Define an appropriate search space to tune over. We want to explore a range between $1$ and $100$ for `n_neighbors`\n",
        "and the distance calculation to be chosen from \u201duniform\u201d, \u201dmanhattan\u201d, \u201deuclidean\u201d, \u201dcosine\u201d."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb600a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef6b7569",
      "metadata": {},
      "source": [
        "> c) Perform the tuning procedure using `RandomizedSearchCV`. Use $5$-fold cross validation, and terminate the process\n",
        "after $200$ iterations. Also, utilize parallelization to fasten the computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85279f3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2211ae",
      "metadata": {},
      "source": [
        "> d) You realize that a high AUC is the performance measure you are actually interested in. Modify the HPO\n",
        "procedure such that performance is optimized w.r.t. AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b800f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b25b9819",
      "metadata": {},
      "source": [
        "> e) You are interested in possible under- and overfitting of your hyperparameter setting. Use validation curve\n",
        "from `sklearn.model_selection` to retrieve the training scores and cross-validation scores for a $5$-fold-CV,\n",
        "depending on the AUC metric. <br>\n",
        "Visualize the tuning result with a suitable command. You may use the function provided below or a self-defined\n",
        "function. <br>\n",
        "Re-run the evaluation with unscaled features.<br>\n",
        "What do you observe regarding the impact of different hyperparameters and scaling on predictive performance?\n",
        "What are limits of such a form of analysis?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1182ea6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07c03d03",
      "metadata": {},
      "source": [
        "> f) After analyzing the tuning results, you notice that changes in `n_neighbors` are more influential for smaller\n",
        "neighborhoods. Re-run the HPO procedure with a log-transformation for `n_neighbors` parameter list.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5484bee5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cba8cb51",
      "metadata": {},
      "source": [
        "> g) With the hyperparameter configuration found via HPO, fit the model on all training observations and compute\n",
        "the AUC on your test data. Could you see any effect of the log-transformation for `n_neighbors`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410fc312",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter your code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c5b213",
      "metadata": {},
      "source": [
        "Function for plotting a validation curve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7226894a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: hint\n",
        "def plot_validation(train_scores, test_scores, param, param_range):\n",
        "    \"\"\"\n",
        "    Plot the validation curve for a given hyperparameter.\n",
        "    Parameters:\n",
        "    ----------\n",
        "    train_scores : array-like of shape (n_param_values, n_folds)\n",
        "    Training scores for each hyperparameter value and fold.\n",
        "    test_scores : array-like of shape (n_param_values, n_folds)\n",
        "    Test scores (e.g., cross-validation scores) for each hyperparameter value and fold.\n",
        "    param : str\n",
        "    Name of the hyperparameter being varied.\n",
        "    param_range : array-like of shape (n_param_values,)\n",
        "    Range of values for the hyperparameter.\n",
        "    Returns:\n",
        "    -------\n",
        "    None\n",
        "    The function plots the validation curve.\n",
        "    \"\"\"\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    \n",
        "    plt.title(\"Validation Curve with KNN\")\n",
        "    plt.xlabel(param)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.0, 1.1)\n",
        "    lw = 2\n",
        "    plt.plot(\n",
        "        param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=lw\n",
        "    )\n",
        "    plt.fill_between(\n",
        "        param_range,\n",
        "        train_scores_mean - train_scores_std,\n",
        "        train_scores_mean + train_scores_std,\n",
        "        alpha=0.2,\n",
        "        color=\"darkorange\",\n",
        "        lw=lw,\n",
        "    )\n",
        "    plt.plot(\n",
        "        param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=lw\n",
        "    )\n",
        "    plt.fill_between(\n",
        "        param_range,\n",
        "        test_scores_mean - test_scores_std,\n",
        "        test_scores_mean + test_scores_std,\n",
        "        alpha=0.2,\n",
        "        color=\"navy\",\n",
        "        lw=lw,\n",
        "    )\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (I2ML)",
      "language": "python",
      "name": "python-i2ml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}