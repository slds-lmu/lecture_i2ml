\documentclass[a4paper]{article}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R




\usepackage[utf8]{inputenc}
%\usepackage[ngerman]{babel}
\usepackage{a4wide,paralist}
\usepackage{amsmath, amssymb, xfrac, amsthm}
\usepackage{dsfont}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{framed}
\usepackage{multirow}
\usepackage{bytefield}
\usepackage{csquotes}
\usepackage[breakable, theorems, skins]{tcolorbox}
\usepackage{hyperref}
\usepackage{cancel}
\usepackage{bm}


\input{../../style/common}

\tcbset{enhanced}

\DeclareRobustCommand{\mybox}[2][gray!20]{%
	\iffalse
	\begin{tcolorbox}[   %% Adjust the following parameters at will.
		breakable,
		left=0pt,
		right=0pt,
		top=0pt,
		bottom=0pt,
		colback=#1,
		colframe=#1,
		width=\dimexpr\linewidth\relax,
		enlarge left by=0mm,
		boxsep=5pt,
		arc=0pt,outer arc=0pt,
		]
		#2
	\end{tcolorbox}
	\fi
}

\DeclareRobustCommand{\myboxshow}[2][gray!20]{%
%	\iffalse
	\begin{tcolorbox}[   %% Adjust the following parameters at will.
		breakable,
		left=0pt,
		right=0pt,
		top=0pt,
		bottom=0pt,
		colback=#1,
		colframe=#1,
		width=\dimexpr\linewidth\relax,
		enlarge left by=0mm,
		boxsep=5pt,
		arc=0pt,outer arc=0pt,
		]
		#2
	\end{tcolorbox}
%	\fi
}


%exercise numbering
\renewcommand{\theenumi}{(\alph{enumi})}
\renewcommand{\theenumii}{\roman{enumii}}
\renewcommand\labelenumi{\theenumi}


\font \sfbold=cmssbx10

\setlength{\oddsidemargin}{0cm} \setlength{\textwidth}{16cm}


\sloppy
\parindent0em
\parskip0.5em
\topmargin-2.3 cm
\textheight25cm
\textwidth17.5cm
\oddsidemargin-0.8cm
\pagestyle{empty}

\newcommand{\kopf}[1] {
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Introduction to Machine Learning \hfill #1. Exercise\\
	 \url{https://introduction-to-machine-learning.netlify.app/} \hfill WiSe 2020/2021}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newenvironment{allgemein}
	{\noindent}{\vspace{1cm}}

\newcounter{aufg}
\newenvironment{aufgabe}
	{\refstepcounter{aufg}\textbf{Exercise \arabic{aufg}:}\\ \noindent}
	{\vspace{0.5cm}}

\newcounter{loes}
\newenvironment{loesung}
	{\refstepcounter{loes}\textbf{Solution \arabic{loes}:}\\\noindent}
	{\bigskip}
	
\newenvironment{bonusaufgabe}
	{\refstepcounter{aufg}\textbf{Exercise \arabic{aufg}*\footnote{This
	is a bonus exercise.}:}\\ \noindent}
	{\vspace{0.5cm}}

\newenvironment{bonusloesung}
	{\refstepcounter{loes}\textbf{Solution \arabic{loes}*:}\\\noindent}
	{\bigskip}



\begin{document}
% !Rnw weave = knitr



\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

\kopf{1}


\aufgabe{

Identify which type of machine learning (supervised or unsupervised? What type of task?) could be used in these cases:

\begin{enumerate}

  \item[a)] When crossing the alps using the Brenner Autobahn, there is the option to pay electronically in advance. When approaching the toll station, the barrier automatically opens when the number plate was recognised. The recognition happens automatically by a digital camera system.
  \item[b)] Diagnose whether a patient suffers from cancer or not.
  \item[c)] The owner of an internet site wants to protect his system against various violations of the terms of service (bot programs, manipulation of timestamps, etc.)
  \item[d)] An online shopping portal wants to determine products that are automatically offered to registered customers upon login.
  \item[e)] We want to sort our news into different groups.
  \item[f)] We want to sort our Email into Spam/Non-Spam.
  \item[g)] In a supermarket, products that are often bought together are said to be placed side by side on a shelf to increase the sales.
  \item[h)] We want to extract a list of skills from XING.
  \item[i)] We want to know our top customers (i.\,e.\ highest sales, logistics, etc.).
\end{enumerate}
}

\dlz
\aufgabe{

%x <- rnorm(6,1)
%x <- c(0.56, 0.22, 1.7, 0.63, 0.36,1.2)
%y <- c(160,150,175,185,165,170)
%data <- t(cbind(x,y))

Suppose we observe 6 data pairs and want to describe the underlying relationship between target $y$ and feature $\xv$.

\begin{center}
  \begin{tabular}{ | c | c | c | c | c | c | c | }
    \hline
$\xv$ & 0.56 & 0.22 & 1.7 & 0.63 & 0.36 & 1.2 \\ \hline
y & 160 & 150 & 175 & 185 & 165 & 170 \\
    \hline
  \end{tabular}
\end{center}


\begin{itemize}
\item[a)] Assume a standard linear relationship $$\yi = \beta_0 + \beta_1 \xi + \epsi$$ with iid errors $\epsi$ and calculate the least squares estimator $\hat{\bm{\beta}}$ for $\bm{\beta}=(\beta_0, \beta_1)^\top$ manually (+ calculator).


\item[b)] Assume a non-linear relationship (polynomial degree 2) $$\yi = \beta_0 + \beta_1 \xi +\beta_2 (\xi)^2 + \epsi$$ with iid errors $\epsi$ and calculate the least squares estimator $\hat{\bm{\beta}}$ for $\bm{\beta}=(\beta_0, \beta_1, \beta_2)^\top$ with R.
\end{itemize}
}

\dlz

\pagebreak[2]

\aufgabe{

Imagine you work at a bank and have the job to develop a credit scoring model. This means, your model should predict whether a customer applying for a credit will be able to pay it back in the end.

\begin{enumerate}[a)]

\item Is this a supervised or unsupervised learning problem? Justify your answer.
\item How would you set up your data? Which is the target variable, what feature variables could you think of? Do you need labeled or unlabeled data? Justify all answers.
\item Is this a regression or classification task? Justify your answer.
\item Is this "learning to predict" or "learning to explain"? Justify your answer.
\item In classical statistics, you could use e.g. the logit model for this task. This means we assume that the targets are conditionally independent given the features, so $\yi|\xi \ind \yi[j]|\xi[j]$ for all $i,j = 1, \dots, n, i \ne j$, where $n$ is the sample size. We further assume that $\yi|\xi \distas{} Bin(\pi^{(i)})$, where $\pi^{(i)} = \frac{\exp(\thetab^\top\xi)}{1+\exp(\thetab^\top\xi)}$.
Looking at this from a Machine Learning perspective, write down the hypothesis space for this model. State explicitly which parameters have to be learned.
\item In classical statistics, you would estimate the parameters via Maximum Likelihood estimation. (The log-Likelihood of the Logit-Model is: $\sumin\yi\log(\pi^{(i)}) + (1-\yi)(\log(1-\pi^{(i)}))$). How could you use the model assumptions to define a reasonable loss function? Write it down explicitly.
\item Now you have to optimize this risk function to find the best parameters and hence the best model. Describe with a few sentences, how you could do this.

\end{enumerate}

Congratulations, you just designed your first Machine Learning project!

}
\end{document}
