\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-eval.tex}

\newcommand{\titlefigure}{figure_man/roc-pr_edited.png}
\newcommand{\learninggoals}{
\item Understand PR curves 
\item Same as PPV-TPR curve
\item Compare to standard TPR-FPR ROC curve 
}


\title{Introduction to Machine Learning}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\begin{document}

\lecturechapter{Evaluation: Precision-Recall Curves }
\lecture{Introduction to Machine Learning}
\sloppy

\begin{frame}{Precision-Recall Curves}


\only<1>{
\begin{itemize}
  \item Slightly changed ROC plot
  \item Simply plot precision and recall, instead of TPR-FPR
  \item Precision = $\rho_{PPV}$ = $\frac{TP}{TP + FP}$, recall = $\rho_{TPR}$ = $\frac{TP}{TP + FN}$
  \item Might call them TPR-PPV curve
  \item NB: Both metrics don't depend on TNs
\end{itemize}
}

\only<2>{
\begin{itemize}
  \item Might be better for highly imbal data ($\nn \gg \np$) than TPR-FPR
  \item Figure (a): ROC; both learners seem to perform well
  \item Figure (b): PR; visible room for improvement (top-right=best)
  \item PR reveals better that algo 2 has advantage over 1
\end{itemize}
}

\vfill

\begin{figure}
  \centering
  \scalebox{0.9}{\includegraphics{figure_man/roc-pr_edited.png}}
  \tiny
  \\Davis and Goadrich (2006): The Relationship Between Precision-Recall and
  ROC Curves (\href{https://www.biostat.wisc.edu/~page/rocpr.pdf}
  {\underline{URL}}).
  % \tiny{\\ Credit: Jesse Davis and Mark Goadrich \\}
\end{figure}

% {\tiny{Davis and Goadrich (2006): The Relationship Between Precision-Recall and
% ROC Curves (\href{https://www.biostat.wisc.edu/~page/rocpr.pdf}{\underline{URL}}).
% \emph{\url{https://www.biostat.wisc.edu/~page/rocpr.pdf}}}\par}

% Source: http://people.cs.bris.ac.uk/~flach/ICML04tutorial/ROCtutorialPartI.pdf
%\tiny{Source for material: https://www.biostat.wisc.edu/~page/rocpr.pdf}
%\tiny{Source for material: https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba}
%\tiny{Source for material: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/}
%\tiny{Source 6: http://binf.gmu.edu/mmasso/ROC101.pdf}
% Source: https://link.springer.com/content/pdf/10.1007/s10994-006-8199-5.pdf


\end{frame}

\begin{vbframe}{Imbalanced data}

\begin{itemize}
     \item Assume imbalanced classes with $\nn \gg \np$
     \item If neg class large, typically less interested in high TNR = low FPR,
     but more in PPV
     \item Large (abs) change in FP yields small change in FPR
  \item PPV likely more informative
\end{itemize}

\lz

\begin{columns}
 \begin{column}{0.45\textwidth}
 \underline{FP=10}:\\
 %Proportion $\np/\nn = 1$\\
 \lz
 {
 \tiny
 \centering
 \tiny
 \begin{tabular}{|l|c|c|}
                 \hline
                & True +1 & True -1 \\ \hline
 Pred. Pos & 100            & 10            \\ \hline
 Pred. Neg & 10            & 9990           \\ \hline
 Total  & 110            & 10000           \\ \hline
 \end{tabular}
 }

 \medskip
 %$\text{E} = 35/100 = 0.35$\\
 $\text{TPR} = 10/11$\\
 $\text{FPR} = 0.001$\\
 $\text{PPV} = 10/11$
\end{column}
\begin{column}{0.45\textwidth}
 \underline{FP=100}:\\
%%  Proportion $\np/\nn = 2$\\
 \lz
 {
 \tiny
 \begin{tabular}{|l|c|c|}
                 \hline
                & True +1 & True -1 \\ \hline
 Pred. +1 & 100            & 100            \\ \hline
 Pred. -1 & 10            & 9900           \\ \hline
 Total  & 110            & 10000           \\ \hline
 \end{tabular}
 }

 \medskip
 $\text{TPR} = 10/11$\\
 $\text{FPR} = 0.01$\\
 $\text{PPV} = 1/2$
\end{column}
\end{columns}

\vfill

RHS: Given test says +1, it's now a coin flip that this is correct.

%\begin{center}
%  \includegraphics[width=0.8\textwidth]{figure_man/roc-confusion_matrix.png}
%\end{center}

% \begin{itemize}
%   \item ROC problem is $FPR$ in case of $\nn \gg \np$, which is often
%   very small as TNs are usually high \\
%   $\Rightarrow$ Large change in FP yields small change in $FPR$
%   \item PPV: compares FP to TP (not TN) and does not suffer from this
%   issue. Captures effect of large $\nn$.
% \end{itemize}

% \begin{center}
%   \includegraphics[width=0.8\textwidth]{figure_man/roc-confusion_matrix.png}
% \end{center}

\framebreak

% \begin{footnotesize}

\vspace{-0.2cm}
\begin{itemize}
  \item Top row: Imbal classes with $\pi = 0.003$
  \item Bottom: balanced with $\pi = 0.5$
  % \item Task and learners remain the same, only class distribution has changed.
  \item ROC curves (LHS) are similar
  \item PR curve (RHS) changes strongly from imbal to bal classes
  %\item Note that the superiority of classifiers in terms of performance can change with a skewed class distribution.
\end{itemize}

% \end{footnotesize}

%replaced graph: (too small)
% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{figure_man/roc-pr-all.png}
%     \tiny{\\ Credit: Tom Fawcett \\}
% \end{figure}
% {\tiny{Tom Fawcett (2004): ROC Graphs: Notes and Practical Considerations for Researchers. \emph{\url{http://binf.gmu.edu/mmasso/ROC101.pdf}}}\par}

\begin{figure}
  \centering
  \scalebox{0.55}{\includegraphics[width=\textwidth]
  {figure_man/roc-pr-imbalanced_edited.png}}
  \tiny
  \\ Wissam Siblini et. al. (2004): Master your Metrics with Calibration
  (\href{https://arxiv.org/pdf/1909.02827.pdf}{\underline{URL}}).
  % \tiny{\\ Wissam Siblini et. al. (2004): Master your Metrics with Calibration.
  % \emph{\url{https://arxiv.org/pdf/1909.02827.pdf}}}\par
  % \tiny{\\ Credit: Wissam Siblini et. al. \\}
\end{figure}

% \vspace{-0.25cm}
%
% {\tiny{Wissam Siblini et. al. (2004): Master your Metrics with Calibration. \emph{\url{https://arxiv.org/pdf/1909.02827.pdf}}}\par}

\end{vbframe}

\begin{vbframe}{Conclusions}

\begin{itemize}
 \item Curve fully dominates in ROC space iff dominates in PR-space
 \item In imbalanced situations rather use PR than standard TPR-FPR
 \item If comparing few models on a single task, probably plot both.\\
 Then observe and think.
\item For tuning: can also use PR-AUC (or partial versions)
\end{itemize}

\vfill

\begin{figure}
  \centering
  \scalebox{0.9}{\includegraphics{figure_man/roc-pr_edited.png}}
  \tiny
  \\Davis and Goadrich (2006): The Relationship Between Precision-Recall and
  ROC Curves (\href{https://www.biostat.wisc.edu/~page/rocpr.pdf}
  {\underline{URL}}).
  % \tiny{\\ Credit: Jesse Davis and Mark Goadrich \\}
\end{figure}
\end{vbframe}

\endlecture
\end{document}

