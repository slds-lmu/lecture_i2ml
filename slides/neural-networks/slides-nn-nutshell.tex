\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

\title{Introduction to Machine Learning}

\begin{document}

\titlemeta{% Chunk title (example: CART, Forests, Boosting, ...), can be empty
  Neural Networks
  }{% Lecture title  
  In a Nutshell
}{% Relative path to title page image: Can be empty but must not start with slides/
  figure_man/nutshell-nn-hidden-layers.png
}{% Learning goals, wrapped inside itemize environment
  \item Know basic computational unit
  \item Know basic architecture
  \item Understand Learning in NNs
}

\sloppy

\begin{vbframe}{Basic Computational Unit: Perceptron}

%\begin{minipage}[t]{0.45\textwidth}

\begin{columns}
\begin{column}{0.6\textwidth}
\begin{center}
%https://docs.google.com/presentation/d/1JuGRuMWOq7lAsECxgQC3C70_3kiW-ZTk/edit#slide=id.p1
\includegraphics[width = \textwidth]{figure_man/nutshell-nn-perceptron.png}
\end{center}
\end{column}
\begin{column}{0.4\textwidth}
\begin{center}
\small Output differs depending on activation function:
\begin{itemize}
    \small \item \textbf{Identity function}: Perceptron represents linear regression
    \small \item \textbf{Logistic function}:  Perceptron represents logistic regression
    \small \item Other activation functions possible
\end{itemize}
\end{center}
\end{column}
\end{columns}
\end{vbframe}

\begin{vbframe}{Basic Architecture of NN}
\small A neural network is built by combination of multiple perceptrons:

\vspace{0.5cm}
%https://docs.google.com/presentation/d/1Vnc1wUgx5z-oZ5QYJu0DrWTX4AiW-rO8/edit#slide=id.p1
\includegraphics[width = 0.95\textwidth]{figure_man/nutshell-nn-basic-architecture.png}    
\end{vbframe}

\begin{vbframe}{Basic Architecture of NN}
Hidden Layers: 
     \begin{itemize}
         \item  Output of hidden units serves as input for units in next layer
         \item Too many hidden layers or too many units per layer can lead to overfitting
     \end{itemize}
Output Layer:
    \begin{itemize}
        \item Number of output units depend on task
        \item Different activation functions for output layer and hidden layers possible
    \end{itemize}

\end{vbframe}

\begin{vbframe}{Learning - Image Classification Task}
\vspace{0.5cm}
% https://docs.google.com/presentation/d/1Fz-D4ldSz02TdGPBwIoT4DSV6Iyr_xpz/edit#slide=id.p1
\begin{center}
    \includegraphics[width = 0.5\textwidth]{figure_man/nutshell-nn-learning-iteration.png}   
\end{center}

\end{vbframe}

\begin{vbframe}{Learning - Image Classification Task}
\vspace{0.5cm}
\begin{center}
%https://docs.google.com/presentation/d/1Fz-D4ldSz02TdGPBwIoT4DSV6Iyr_xpz/edit#slide=id.p1
   \includegraphics[width = \textwidth]{figure_man/nutshell-nn-learning-forwardpass.png}    
\end{center}
 
\end{vbframe}

\begin{vbframe}{Learning - Image Classification Task}
\small Compute update of each weight by backpropagation
\vspace{0.5cm}
\begin{center}
%https://docs.google.com/presentation/d/1Vmt8zfzmbB-cAL5lhj-YnagU2T8Ir190/edit#slide=id.p1
   \includegraphics[width = 0.9\textwidth]{figure_man/nutshell-nn-learning-backpropagation.png}    
\end{center}    
\end{vbframe}



\begin{vbframe}{Prediction - Image Classification Task}
\vspace{0.5cm}
\begin{center}
%https://docs.google.com/presentation/d/1h20Ijl1YxCXVE2JoLQ4K-PdoJcQYo2Vo/edit#slide=id.p1
   \includegraphics[width = \textwidth]{figure_man/nutshell-nn-prediction.png}    
\end{center}

\end{vbframe}


\begin{vbframe}{Effect of hidden layers}
\begin{itemize}
    \small \item Learn more and more abstract representations
    \small \item Each layer adds degree of non-linearity
\end{itemize}
\vspace{1cm}
\begin{center}
%https://docs.google.com/presentation/d/1moiTW7umxr30Mg9iMfNCBBpqPpjYJv0Y/edit#slide=id.p1
   \includegraphics[width = \textwidth]{figure_man/nutshell-nn-hidden-layers.png}    
\end{center}

\end{vbframe}


\endlecture
\end{document}
