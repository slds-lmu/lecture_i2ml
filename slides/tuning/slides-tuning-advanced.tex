\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}

\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/ml-hpo.tex}
\input{../../latex-math/ml-eval.tex}

\title{Introduction to Machine Learning}


\begin{document}

\titlemeta{% Chunk title (example: CART, Forests, Boosting, ...), can be empty
  Hyperparameter Tuning
  }{% Lecture title  
  Advanced Tuning Techniques
}{% Relative path to title page image: Can be empty but must not start with slides/
figure/seq_1d_bo4.pdf
}{% Learning goals, wrapped inside itemize environment

\item Basic idea of evolutionary algorithms
\item and Bayesian Optimization
\item and hyperband
}

\sloppy


\begin{vbframe}{HPO -- Many approaches}
\begin{itemize}
    \item Evolutionary algorithms
    \item Bayesian / model-based optimization
    \item Multi-fidelity optimization, e.g.\ Hyperband
\end{itemize}

\includegraphics[width = 0.37\textwidth]{figure/ea.eps}
\includegraphics[width = 0.37\textwidth]{figure/mbo.png}
\includegraphics[trim=0 0 285 0, clip, width = 0.235\textwidth]{figure/hyperband.png}

HPO methods can be characterized by: 
\begin{itemize}
    \item how the exploration vs. exploitation trade-off is handled
    \item how the inference vs. search trade-off is handled% (how much time is spent is spent to learn a surrogate model on the currently observed data)
\end{itemize}

Further aspects: Parallelizability, local vs. global behavior, handling of noisy observations, multifidelity and search space complexity. 

\end{vbframe}

\begin{vbframe}{Evolutionary strategies}

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.65\textwidth]{figure/ea.eps}
%    \caption{%
%        Schematic representation of a single iteration of an ES as a four dimensional discrete problem.
%        Parameter values are symbolized by geometric shapes.
%    }
    \label{fig:ea}
\end{figure}
\begin{footnotesize}
\begin{itemize}
\item Are  a  class  of  stochastic  population-based  optimization  methods  inspired  by  the  concepts  of  biological  evolution
\item Are applicable to HPO since they  do  not  require  gradients
\item Mutation is  the  (randomized)  change  of  one  or  a  few  HP  values  in  a  configuration.
\item Crossover creates a new HPC by (randomly) mixing the values of two other configurations. 
\end{itemize}
\end{footnotesize}

\end{vbframe}

\begin{vbframe}{Bayesian Optimization}
BO sequentially iterates:
\begin{columns}
\column{0.45\textwidth}
\begin{enumerate}
\item \textbf{Approximate} $\bm{\lambda} \mapsto c(\bm{\lambda})$ by  (nonlin) regression model $\hat c(\bm{\lambda})$, from evaluated configurations (archive)
\item \textbf{Propose candidates} via optimizing an acquisition function that is based on the surrogate $\hat c(\bm{\lambda})$
\item \textbf{Evaluate} candidate(s) proposed in 2, then go to 1 
\end{enumerate}
\column{0.5\textwidth}
\vspace*{0.5cm}
\includegraphics[width = 1\textwidth]{figure/mbo.png}
\end{columns}
Important trade-off: \textbf{Exploration} (evaluate candidates in under-explored areas) vs. \textbf{exploitation} (search near promising areas)

\end{vbframe}

\begin{frame}{Bayesian Optimization}

\begin{columns}
\column{0.45\textwidth}
\textbf{Surrogate Model}: 
\begin{itemize}
    \item Probabilistic modeling of $C(\lamv) \sim (\hat c(\bm{\lambda}), \hat \sigma(\bm{\lambda}))$ with posterior mean $\hat c(\bm{\lambda})$ and uncertainty  $\hat \sigma(\bm{\lambda})$.  
    \item Typical choices for numeric spaces are Gaussian Processes; random forests for mixed spaces
\end{itemize}
\column{0.5\textwidth}
\vspace*{0.5cm}
\includegraphics[width = 1\textwidth]{figure/mbo.png}
\end{columns}

\textbf{Acquisition Function}: 
\begin{itemize}
    \item Balance exploration (high $\hat \sigma$) vs. exploitation (low $\hat c$). 
    \item Lower confidence bound (LCB): $\quad a(\bm{\lamv}) = \hat c(\bm{\lambda}) - \kappa \cdot \hat \sigma(\lamv)$ 
    \item Expected improvement (EI): $\quad a(\lamv) = \E\left[\max\left\{c_{\min} - C(\lamv), 0\right\}\right]$ where ($c_{\min}$ is best cost value from archive)
    %($c_{\min}$ is best observed value)
    \item Optimizing $a(\lamv)$ is still difficult, but cheap(er)
\end{itemize}

\end{frame}

\begin{vbframe}{Bayesian Optimization}

% Model-based optimization (MBO) is a sequential optimization procedure. We start with an initial design, i.e., a set of configurations $\lambda_i$ where we have evaluated the corresponding (resampling) performance. 
% 
% Repeat:
%   \begin{enumerate}
% \item From the available performance measurements, we build a \textbf{surrogate model} that models the relationship between model hyperparameters and estimated generalization error. It serves as a cheap approximation of the expensive objective. 
% \item Based on information provided by the surrogate model, a new configuration $\lambda^{(\text{new})}$ is proposed: we pick a value for which the surrogate model predicts a large potential improvement over the already evaluated configurations.
% \item The resampling performance of the learner with hyperparameter setting $\lambda^{(\text{new})}$ is evaluated and added to the set of design points.  
% \end{enumerate}

%\framebreak 

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=0.95\textwidth]{figure/seq_1d_bo1.pdf} 

}
%FIGURE SOURCE: fig-cart_tuning_ad_1.R


\end{knitrout}
  
  \begin{footnotesize}
Upper plot: The surrogate model (black, solid) models the \emph{unknown} relationship between input and output (black, dashed) based on the initial design (red points).\\
Lower plot: Mean and variance of the surrogate model are used to derive the expected improvement (EI) criterion. The point that maximizes the EI is proposed (green point). 
\end{footnotesize}


\end{vbframe}
\begin{vbframe}{Bayesian Optimization}
\addtocounter{framenumber}{-1}

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=0.95\textwidth]{figure/seq_1d_bo2.pdf} 
}
%FIGURE SOURCE: fig-cart_tuning_ad_1.R


\end{knitrout}
  \begin{footnotesize}
Upper plot: The surrogate model (black, solid) models the \emph{unknown} relationship between input and output (black, dashed) based on the initial design (red points).\\
Lower plot: Mean and variance of the surrogate model are used to derive the expected improvement (EI) criterion. The point that maximizes the EI is proposed (green point). 
\end{footnotesize}

\end{vbframe}



\begin{vbframe}{Bayesian Optimization}
\addtocounter{framenumber}{-1}

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=0.95\textwidth]{figure/seq_1d_bo3.pdf} 
}
%FIGURE SOURCE: fig-cart_tuning_ad_1.R


\end{knitrout}
  \begin{footnotesize}
Upper plot: The surrogate model (black, solid) models the \emph{unknown} relationship between input and output (black, dashed) based on the initial design (red points).\\
Lower plot: Mean and variance of the surrogate model are used to derive the expected improvement (EI) criterion. The point that maximizes the EI is proposed (green point). 
\end{footnotesize}

\end{vbframe}
\begin{vbframe}{Bayesian Optimization}
\addtocounter{framenumber}{-1}

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=0.95\textwidth]{figure/seq_1d_bo4.pdf} 
}
%FIGURE SOURCE: fig-cart_tuning_ad_1.R


\end{knitrout}
  \begin{footnotesize}
Upper plot: The surrogate model (black, solid) models the \emph{unknown} relationship between input and output (black, dashed) based on the initial design (red points).\\
Lower plot: Mean and variance of the surrogate model are used to derive the expected improvement (EI) criterion. The point that maximizes the EI is proposed (green point). 
\end{footnotesize}
\framebreak

Since we use the sequentially updated surrogate model predictions of performance to propose new configurations,
we are guided to \enquote{interesting} regions of $\bm{\Lambda}$ and avoid irrelevant evaluations:
  
  \begin{center}
\begin{figure}
% see rsrc/mbo-example.R
\includegraphics[width=0.6\textwidth]{figure/mbo_random_tune.pdf}
\caption{\footnotesize{Tuning complexity and minimal node size for splits for CART on the \texttt{titanic} data (10-fold CV maximizing accuracy). \\
  Left panel: BO, 50 configurations; right panel: random search, 50 iterations. \\
  Top panel: one run (initial design of BO is white); bottom panel:  mean $\pm$ std of 10 runs.}}
\end{figure}
\end{center}


\end{vbframe}


\begin{vbframe}{Multifidelity optimization}
\begin{itemize}
\item Prerequiste: Fidelity  HP $\lamfid$, i.e.,  a  component  of $\lamv$,  which  influences  the computational  cost  of  the  fitting  procedure  in  a  monotonically  increasing  manner
\item Methods of multifidelity optimization in HPO are all tuning  approaches  that  can  efficiently handle  a $\ind$ with  a  HP $\lambda_{\text{fid}}$
\item The  lower  we  set $\lamfid$,  the more points we can explore in our search space, albeit with much less reliable information w.r.t. their true performance.
\item We  assume  to  know  box-constraints  of $\lamfid$,  so $\lamfid \in [\lamfidl, \lamfidu]$,  where  the  upper  limit  implies  the  highest  fidelity  returning  values closest to the true objective value at the highest computational cost. 
\end{itemize}
\end{vbframe}

\begin{vbframe}{Successive Halving}

\begin{columns}
\column{0.59\textwidth}
\begin{itemize}
\item Races down set of HPCs to the best
\item Idea: Discard bad configurations early
\item Train HPCs with fraction of full budget (SGD epochs, training set size); the control param for this is called \textbf{multi-fidelity HP}
\item Continue with better $1/\eta$ fraction of HPCs (w.r.t $\GEh{}$); 
with $\eta$ times budget (usually $\eta = 2,3$)
\item Repeat until budget depleted or single HPC remains
\end{itemize}
\column{0.41\textwidth}
\begin{center}
\includegraphics[trim=0 0 100 0, clip, width = 1.0\textwidth]{figure/hyperband.eps}
\end{center}
\end{columns}
\end{vbframe}

\begin{vbframe}{Multifidelity optimization -- Hyperband}

\begin{columns}
\column{0.70\textwidth}
\textbf{Problem with SH}
\begin{itemize}
    \item Good HPCs could be killed off too early, 
    depends on evaluation schedule
\end{itemize}
\textbf{Solution: Hyperband}
\begin{itemize}
\item Repeat SH with different start budgets $\lambda_{\text{fid}}^{[0]}$ and initial number of HPCs $p^{[0]}$ 
\item Each SH run is called bracket
\item Each bracket consumes ca. the same budget
%\item It is a multi-fidelity optimization method since it uses information of multiple fidelity levels to identify promising candidates
\end{itemize}
\column{0.30\textwidth}
\begin{footnotesize}
For $\eta = 4$ 
\begin{center}
bracket 3
\begin{tabular}{ l l l }
$t$ & $\lambda_{\text{fid}}^{[t]}$ & $p_3^{[t]}$ \\
\hline 
0 & 1 & 82 \\
1 & 4 & 20 \\
2 & 16 & 5 \\
3 & 64 & 1
\end{tabular} \\
\medskip
bracket 2
\begin{tabular}{ l l l }
$t$ & $\lambda_{\text{fid}}^{[t]}$ & $p_2^{[t]}$ \\
\hline 
0 & 4 & 27 \\
1 & 16 & 6 \\
2 & 64 & 1
\end{tabular} \\
\medskip
bracket 1
\begin{tabular}{ l l l }
$t$ & $\lambda_{\text{fid}}^{[t]}$ & $p_1^{[t]}$ \\
\hline 
0 & 16 & 10 \\
1 & 64 & 2
\end{tabular} \\
\medskip
bracket 0
\begin{tabular}{ l l l }

$t$ & $\lambda_{\text{fid}}^{[t]}$ & $p_0^{[t]}$ \\
\hline 
0 & 64 & 5
\end{tabular}

\end{center}
\end{footnotesize}
\end{columns}
\end{vbframe}

% \begin{vbframe}{Hyperband}
% 
% \begin{itemize}
% \item It is extremely expensive to train complex models on large data sets
% \item For many configurations, it might be clear early on that further training is not likely to significantly improve the performance
% \item More importantly, the relative ordering of configurations (for a given data set) can also become evident early on. 
% \item \textbf{Idea:} \enquote{weed out} poor configurations early during training
% \item One approach is \textbf{successive halving}: Given an initial set of configurations, all trained for a small initial budget, repeat:
%   \begin{itemize}
% \item Remove the half that performed worst, double the budget
% \item Continue until the new budget is exhausted
% \end{itemize}  
% \item Successful halving is performed several times with different trade-offs between the number of configurations considered and the budget that is spent on them. 
% \end{itemize}
% 
% \framebreak 
% 
% Only the most promising configuration(s) are trained to completion: 
%   
%   \begin{center}
% \begin{figure}
% \includegraphics[width=0.8\textwidth]{figure_man/hyperband3.png}
% %src: https://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf
% \end{figure}
% \end{center}
% \tiny taken from Hutter, Kotthoff, Vanschoren. \textit{Automated Machine Learning -- Methods, Systems, Challenges}. Springer, 2019. (Fig. 1.3)
% \end{vbframe}

\begin{frame}{More tuning algorithms:}

Other advanced techniques besides model-based optimization and the hyperband algorithm are: 
  
  \begin{itemize}
\item Stochastic local search, e.g., simulated annealing
\item Genetic algorithms / CMAES
\item Iterated F-Racing
\item Many more $\ldots$
  \end{itemize}

\medskip
For more information see \textit{Hyperparameter Optimization: Foundations, Algorithms,
Best Practices and Open Challenges}, Bischl (2021)

\end{frame}
\endlecture
\end{document}
