\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R



\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage{dsfont}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{colortbl}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{bm}
\usetikzlibrary{shapes,arrows,automata,positioning,calc,chains,trees, shadows}
\tikzset{
  %Define standard arrow tip
  >=stealth',
  %Define style for boxes
  punkt/.style={
    rectangle,
    rounded corners,
    draw=black, very thick,
    text width=6.5em,
    minimum height=2em,
    text centered},
  % Define arrow style
  pil/.style={
    ->,
    thick,
    shorten <=2pt,
    shorten >=2pt,}
}
\usepackage{subfig}


% Defines macros and environments
\input{../../style/common.tex}

%\usetheme{lmu-lecture}
\newcommand{\titlefigure}{figure_man/riskmin_bilevel3.png}
\newcommand{\learninggoals}{
\item Understand the definition of $c$ and know its properties
\item Know the components of a tuning problem
\item Be able to explain what makes tuning a complex problem}
\usepackage{../../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}

\title{Introduction to Machine Learning}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle}



\begin{document}

% Load all R packages and set up knitr

% This file loads R packages, configures knitr options and sets preamble.Rnw as parent file
% IF YOU MODIFY THIS, PLZ ALSO MODIFY setup.Rmd ACCORDINGLY...








% Defines macros and environments
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-eval.tex}
\input{../../latex-math/ml-hpo.tex}

%! includes: tuning-intro

\lecturechapter{Hyperparameter Tuning - Problem Definition }
\lecture{Introduction to Machine Learning}
\sloppy

\begin{vbframe}{HPO as black-box optimization}

\vskip 3em
Recall: \textbf{Hyperparameters (HP)} $\lamv$ are parameters that are \emph{inputs} to the 
training problem in which a learner $\inducer$ minimizes the empirical risk on a training data set in order
to find optimal \textbf{model parameters} $\thetab$ which define the fitted model $\fh$. Usually  HPs influence the generalization  performance in  a  non-trivial  and  subtle  way. 

\vskip 2em

\textbf{Hyperparameter optimization (HPO) / Tuning} is the process of finding good model hyperparameters $\lamv$. 

% \begin{vbframe}{Hyperparameter Tuning}
% \begin{itemize}
% \item Optimize hyperparameters for learner w.r.t. prediction error
% Tuner proposes configuration, eval by resampling, tuner receives performance, iterate
% \end{itemize}
% \begin{columns}[c, onlytextwidth]
% \column{0.45\textwidth}
% FIGURE SOURCE: No source
  % \includegraphics[trim={0cm 0cm 0cm 0cm}, clip, width=1.2\textwidth]{figure_man/chain.jpg}
% \column{0.45\textwidth}
  % FIGURE SOURCE: https://drive.google.com/open?id=1wY3aUZxIMZPje3vR0t2yWiDMx_osXRCi
% \includegraphics[trim={1cm 0cm 1cm 0cm}, clip, width=1.2\textwidth]{figure_man/tuning_process.jpg}
% \end{columns}

% \end{vbframe}

\framebreak
\begin{itemize}
\item HPO  algorithms  automatically identify  a  well-performing  hyperparameter configuration (HPC) $\lamv \in \LamS$ for an learner $\Ilam$. 
\item As input they take the search space $\LamS \subset \Lam$ which contains all considered HPs for optimization and their respective ranges:
$$\LamS = \LamS_1 \times \LamS_2 \times \dots \times \LamS_l$$
 where $\LamS_i$ is a bounded subset of the domain of the i-th HP $\Lam_i$,  and can be either continuous, discrete, or categorical. 
\end{itemize}

\framebreak
The general HPO problem is defined as:
\begin{eqnarray*}
    \lams \in \argmin_{\lamv \in \LamS} \clam = \argmin_{\lamv \in \LamS} 
    %\GEhlamsubIJrho
    \GEhresa
\end{eqnarray*}
where $\lams$ denotes the theoretical optimum, and $\clam$ is a shorthand for the estimated generalization error when $\inducer$, resampling splits $\JJ$, performance measure $\rho$ are fixed.

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.75\textwidth]{figure/hpo_loop_1.eps}
    %{figures/riskmin_bilevel3.png}
\end{figure}

\framebreak

\begin{itemize}
\item This means we estimate and optimize the generalization error 
\begin{equation*}
\small
\begin{split}
\clam = \GEhresa = \agr\Big(
 &\rho\Big(\yv_{\Jtesti[1]}, \FJtestftraini[1]\Big), \\ &\large{\vdots} \\
& \rho\Big(\yv_{\Jtesti[1]}, \FJtestftraini[B]\Big)
    \Big),
\end{split}
\end{equation*}
of a learner $\Ilam$, w.r.t.\ an HPC $\lamv$
\item  $\clam$ is a black-box, as it usually has no closed-form mathematical representation, and hence no analytic gradient information is available. 
\item The evaluation of $\clam$ can take a significant amount of time.
\item Therefore, the minimization of $\clam$ forms an \emph{expensive black-box} optimization problem.
\end{itemize}

\end{vbframe}


\begin{vbframe}{Tuning components} 

% \vspace{0.2cm} 
% 
% We face a \textbf{bi-level} optimization problem: The well-known risk minimization problem to find $\fh$ is \textbf{nested} within the outer hyperparameter optimization (also called second-level problem):
% 
% \begin{center}
% \begin{figure}
% % FIGURE SOURCE: https://docs.google.com/presentation/d/14xwcs5zncTjFL4hIHAprjZMmyGIPqk5vs8DS32vEAvQ/edit?usp=sharing
% \includegraphics[width=0.8\textwidth]{figure_man/riskmin_bilevel3.png}
% \end{figure}
% \end{center}
% 
% \framebreak
%   \footnotesize
%   \begin{itemize}
%     \item For a learning algorithm $\inducer$ (also inducer) with $d$ hyperparameters, the hyperparameter \textbf{configuration space} is:
%       $$\Lam=\Lam_{1} \times \Lam_{2} \times \ldots \times \Lam_{d},$$
%       where $\Lam_{i}$ is the domain of the $i$-th hyperparameter.
%     \item The domains can be continuous, discrete or categorical.
%     \item For practical reasons, the domain of a continuous or integer-valued hyperparameter is typically bounded.
%     \item A vector in this configuration space is denoted as $\bm{\lambda} \in \Lam$.
%     \item A learning algorithm $\inducer$ takes a (training) dataset $\D \in \allDatasets$ and a hyperparameter configuration $\lamv \in \Lam$ and returns a trained model (through risk minimization)
% 
%     \vspace*{-0.2cm}
%   \begin{eqnarray*}
%     \inducer: \preimageInducer &\to& \Hspace \\
%     (\D, \lamv) &\mapsto& \inducer(\D, \lamv) = \hat f_{\D, \lamv}
%   \end{eqnarray*}
%     % \item Additionally, some hyperparameters may only need to be specified if another hyperparameter (or combination of hyperparameters) takes on a certain value.
%   \end{itemize}
% 
%   % \lz 
% 
%   % Note that 
% 
%   %   In contrast to the first-level (empirical) risk minimization problem, hyperparameter optimization is also referred to as \textbf{second-level} optimization. The first-level problem can be seen as a subroutine called by the second-level problem: Each evaluation of $\lamv$ requires to solve the first-level optimization problem.  
% 
% 
% %   \framebreak 
% 
% %   \begin{itemize}
% %     \item search for the \textbf{inducer} hyperparameter $\lamv$
% %     \item that minimizes the \textbf{generalization error}
% %       $$
% %         \min_{\lamv} \E_{\D_n \sim \Pxy, (\xv, y) \sim \Pxy} \left(V\left(y, \hat f_{\D, \lamv}(\xv)\right)\right). 
% %       $$
% %   \end{itemize}
% 
% % We compare: In empirical risk minimization, we 
%   
% %   \begin{itemize}
% %     \item search for the \textbf{model} parameter $\thetab$
% %     \item that minimizes the \textbf{empirical risk}
% %       $$
% %         \min_{\thetab} \sum_{(\xi, \yi) \in \Dtrain} L\left(\yi, \fxi\right). 
% %       $$
% %   \end{itemize}
% 
% %   In hyperparameter optimization, we
% 
% %   \begin{itemize}
% %     \item search for the \textbf{inducer} hyperparameter $\lamv$
% %     \item that minimizes the \textbf{test error}
% %       $$
% %         \min_{\lamv \in \Lam} \sum_{(\xi, \yi) \in \Dtest} V\left(\inducer(\Dtrain, \lamv)(\xi), \yi\right). 
% %       $$
% %   \end{itemize}
% 
% %   \framebreak 
% 
%     % \framebreak
%   
%   % The hyperparameter optimization problem is difficult in many ways: 
%   \end{vbframe}
% 
% 
% \begin{vbframe}{Tuning: A bi-level optimization problem} 
% We formally state the nested hyperparameter tuning problem as: 
% 
% $$
% \min_{\lamv \in \LamS} c(\lamv) \text{ where } c(\lamv) := \GEh_{\Dtrain, \Dtest}(\inducer,
%   \lamv, \ntrain, \rho)
% $$
% 
% \begin{itemize}
% \item The learner $\inducer(\Dtrain, \lamv)$ takes a training data set as well as hyperparameter settings $\lamv$ (e.g., the maximal depth of a classification tree) as an input. 
% \item The search space $\LamS$  is a bounded subset of $\Lam$.
% \item $\inducer(\Dtrain, \lamv)$ performs empirical risk minimization on the training data and returns the optimal model $\fh$ for the given hyperparameters. 
% \item Note that for the estimation of the generalization error, more sophisticated resampling strategies like cross-validation can be used.
% \end{itemize}
% 
% \framebreak

The components of a tuning problem are: 

\begin{itemize}
\item The data set $\D$
\item A learner $\Ilam$ (possibly: several competing learners?) to be tuned %(e.g. a decision tree classifier)
\item The learner's hyperparameters and their respective regions-of-interest $\LamS$ over which we optimize % (e.g. $\texttt{tree depth} \in \{1, 2, ..., 20\}$)
\item The performance measure $\rho$, as determined by the application.\\ Not necessarily identical to the loss function that defines the risk minimization problem for the learner!\\ 
% We could even be interested in multiple measures simultaneously, e.g., accuracy and computation time of our model, TPR and PPV, etc. 
\item A (resampling) procedure for estimating the predictive performance which gives rise to the splits $\JJ$
   % The expected performance on unseen data can be estimated by holdout (i.e., a single train-test-split) or more advanced techniques like cross-validation.
% More on this later.
\end{itemize}
\medskip
We can thus define the HP tuner $\tau: (\D,\inducer,\LamS,\rho)\mapsto \lamh$ that proposes its estimate $\lamh$ of the true optimal configuration $\lams$ given $\D, \Ilam$ with corresponding search space $\LamS$ to optimize, and a target measure $\rho$.

% \framebreak 

% \begin{center}
% \begin{figure}
% FIGURE SOURCE: https://docs.google.com/presentation/d/1JUtguuVBgidcqD0IdFFIiKH9zqYzM6YRjCqC53V90dA/edit?usp=sharing
% \includegraphics[width=1.2\textwidth]{figure_man/autotune_in_model_fit.pdf}
% \end{figure}
% \end{center}

\end{vbframe}




% \framebreak

% Possible scenarios for finding default hyperparameters:

% \begin{itemize}
%   \item If the learner's performance is fairly insensitive to changes of a hyperparameter, we don't really have to worry as long as we remain within the range of reasonable values.
%   \item Constant default: we can benchmark the learner across a broad range of data sets and scenarios and try to find hyperparameter values that work well in many different situations. Quite optimistic?
%   \item Dynamic (heuristic) default: We can benchmark the learner across a broad range of data sets and scenarios and try to find an easily computable function that sets the hyperparameter in a data dependent way,
%   e.g. using \texttt{mtry}$ = p/3$ for RF.\\
%     How to construct or learn that heuristic function, though...?
%   \item In some cases, can try to set hyperparameters optimally by extracting more info from the fitted model. E.g. \texttt{ntrees} for a random forest (does OOB error increase or decrease if you remove trees from the ensemble?).
% \end{itemize}
% \end{vbframe}









\begin{vbframe}{Why is tuning so hard?}
  \begin{itemize}
\item Tuning is derivative-free (\enquote{black box problem}): It is usually impossible to compute derivatives of the objective (i.e., the resampled performance measure) that we optimize with regard to the HPs. All we can do is evaluate the performance for a given hyperparameter configuration.
\item Every evaluation requires one or multiple train and predict steps of the learner. I.e., every evaluation is very \textbf{expensive}.
\item Even worse: the answer we get from that evaluation is \textbf{not exact, but stochastic} in most settings, as we use resampling.
\item Categorical and dependent hyperparameters aggravate our difficulties: the space of hyperparameters we optimize over has a non-metric, complicated structure.
  \end{itemize}

  \end{vbframe}

\endlecture

\end{document}
