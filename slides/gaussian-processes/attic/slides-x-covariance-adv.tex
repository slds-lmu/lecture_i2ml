\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-gp}

\newcommand{\titlefigure}{figure_man/up-crossings.png}
\newcommand{\learninggoals}{
  \item \textcolor{blue}{XXX}
  \item \textcolor{blue}{XXX}
}

\title{Introduction to Machine Learning}
\date{}

\begin{document}

\lecturechapter{Covariance Functions for GPs - Advanced}
\lecture{Introduction to Machine Learning}

\begin{vbframe}{MS-Continuity and Differentiability}

We wish to describe a Gaussian process in terms of its smoothness. There are several notions of continuity for random variables - one is continuity / differentiability in mean square (MS): 

\begin{block}{Definition}
A Gaussian process $f(\xv)$ is said to be 
\begin{itemize}
\item continuous in MS in $\xv_*$, if $\E[|f(\xv^{(k)}) - f(\xv_*)|^2] \overset{k \to \infty}{\longrightarrow} 0$ for any sequence $\xv^{(k)} \overset{k \to \infty}{\to} \xv_*$
\item MS differentiable in direction $i$ if $\lim_{h\to 0}\E[|\frac{f(\xv + h\bm{e}_i) - f(\xv)}{h}|]$ exists, where $\bm{e}_i = (0,\dots,0,1,0,\dots,0)^T$ is the unit vector in the $i$-th axis.
\end{itemize}
\end{block}

\textbf{Remark:} MS continuity / differentiability does not necessarily imply continuity / differentiability of the sampled function! 

\framebreak

MS continuity / differentiability of a Gaussian process can be derived from the smoothness properties of the kernel:

\begin{itemize}
\item The GP is continuous in MS if and only if the covariance function $k(\xv, \xv
^\prime)$ is continuous 
\item The MS derivative of a Gaussian process exists iff the second derivative $\frac{\partial^{2} k(\xv, \xv^\prime)}{\partial \xv\partial \xv^\prime}$ exists
\end{itemize}

\end{vbframe}



\begin{vbframe}{Squared exponential covariance function}

One common used covariance function is the squared exponential covariance function:

$$
k(\xv, \xv^\prime) = \exp\biggl(- \frac{\|\xv - \xv^\prime\|^2}{2\ls^2}\biggr)
$$

\textbf{Properties}:
\begin{itemize}
\item as it depends on the distance $r = \|\xv - \xv^\prime\|$ only, it is a isotropic (and thus also stationary) covariance function
\item infinitely differentiable $\to$ corresponding GP is thus very smooth
\item due to its strong smoothness assumptions it is often unrealistic for modeling many physical processes

\end{itemize}

\end{vbframe}

\begin{vbframe}{Upcrossing Rate and Characteristic Length-Scale}
  
Another way to describe a Gaussian process is the expected number of up-crossings at level $0$ on the unit interval, which we denote by $N_0$. 

\begin{figure}
  \includegraphics[width=0.7\textwidth]{figure_man/up-crossings.png}
\end{figure}

For an isotropic covariance function $k(r)$, it can be shown that the expected number of up-crossings can be calculated explicitly

$$
\E[N_0] = \frac{1}{2\pi} \sqrt{\frac{- k^{\prime \prime}(0)}{k(0)}}.
$$

\framebreak

\textbf{Example:} Squared exponential

\begin{eqnarray*}
k(r) &=& \exp\biggl(-\frac{r^2}{2\ls^2}\biggr)\\
k^\prime(r) &=& - k(r) \cdot \frac{r}{\ls^2} \\
k^{\prime\prime}(r) &=&  k(r) \cdot \frac{r^2}{\ls^4} - k(r) \cdot \frac{1}{\ls^2}
\end{eqnarray*}

The expected number of level-0 upcrossing is thus

$$
\E[N_0] = \frac{1}{2\pi} \sqrt{\frac{- k^{\prime\prime}(0)}{k(0)}} = \frac{1}{2\pi} \sqrt{\frac{1}{\ls^2}} = (2\pi \ls)^{-1}
$$


\end{vbframe} 

\endlecture
\end{document}
