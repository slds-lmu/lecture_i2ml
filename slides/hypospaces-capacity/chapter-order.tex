%Suggested order of slides
% slides-info-entropy
% slides-info-diffent
% slides-info-sourcecoding
% slides-info-kl
% slides-info-cross-entropy-kld
% slides-info-ml
% slides-info-mutual-info


\subsection{Entropy}
\includepdf[pages=-]{../slides-pdf/slides-info-entropy.pdf}

\subsection{Differential Entropy}
\includepdf[pages=-]{../slides-pdf/slides-info-diffent.pdf}

\subsection{Entropy and Optimal Code Length}
\includepdf[pages=-]{../slides-pdf/slides-info-sourcecoding.pdf}

\subsection{Kullback-Leibler Divergence}
\includepdf[pages=-]{../slides-pdf/slides-info-kl.pdf}

\subsection{Cross-Entropy, KL and Source Coding}
\includepdf[pages=-]{../slides-pdf/slides-info-cross-entropy-kld.pdf}

\subsection{Information Theory for Machine Learning}
\includepdf[pages=-]{../slides-pdf/slides-info-ml.pdf}

\subsection{Joint Entropy and Mutual Information}
\includepdf[pages=-]{../slides-pdf/slides-info-mutual-info.pdf}


